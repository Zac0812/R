{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data in R (Part 1)\n",
    "\n",
    "## 1. Importing data from flat files with utils\n",
    "Imagine this situation until now, we have been worked with sheets of Excel to do our Analysis but now we need to star to work with dataframes in R so it´is necessary to read our data from diferrent kind of originen, so in this course you´ll learn to reado dat from:\n",
    "1. Flat File\n",
    "2. Data from Excel\n",
    "3. DataBases\n",
    "4. Web\n",
    "5. Statical Software\n",
    "\n",
    "### Introduction & read.csv\n",
    "The first type of origin of data is \"csv\" (comma separated values), a lot of function that we will use to load or documents are loaded by default when we star R in the **utils** package, so :\n",
    "\n",
    "    read.csv(\"name of document\", stringAsFactor=False)\n",
    "    \n",
    "If our file its out our home directory, it´s necesary to write the path, independs of pc we can use:\n",
    "\n",
    "Notes:\n",
    "\n",
    "We can see our home directory with:\n",
    "\n",
    "    #To know our actual work directory \n",
    "    getwd()\n",
    "    \n",
    "To change our home direcorty:\n",
    "\n",
    "    # Set the working directory or change our directory\n",
    "    setwd(\"D:/Documentos/R\")\n",
    "    \n",
    "If we don´t know our path, we can use the functión file.path to build our path independent our operative system, only need to write all sub directories.\n",
    "\n",
    "    help(\"file.path\")\n",
    "    Directory_State<-file.path(\"D:\",\"Documentos\",\"R\",\"states.csv\")\n",
    "    Directory_State\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'D:/Analista Pricing/6.0 Personal/R'"
      ],
      "text/latex": [
       "'D:/Analista Pricing/6.0 Personal/R'"
      ],
      "text/markdown": [
       "'D:/Analista Pricing/6.0 Personal/R'"
      ],
      "text/plain": [
       "[1] \"D:/Analista Pricing/6.0 Personal/R\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'D:/Documentos/R/states.csv'"
      ],
      "text/latex": [
       "'D:/Documentos/R/states.csv'"
      ],
      "text/markdown": [
       "'D:/Documentos/R/states.csv'"
      ],
      "text/plain": [
       "[1] \"D:/Documentos/R/states.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>state</th><th scope=col>capital</th><th scope=col>pop_mill</th><th scope=col>are_sqm</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>South Dakota</td><td>Pierre      </td><td> 0.853      </td><td>77116       </td></tr>\n",
       "\t<tr><td>New York    </td><td>Albany      </td><td>19.746      </td><td>54555       </td></tr>\n",
       "\t<tr><td>Oregon      </td><td>Salem       </td><td> 3.970      </td><td>98381       </td></tr>\n",
       "\t<tr><td>Vermont     </td><td>Montpelier  </td><td> 0.627      </td><td> 9616       </td></tr>\n",
       "\t<tr><td>Hawaii      </td><td>Honolulu    </td><td> 1.420      </td><td>10931       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " state & capital & pop\\_mill & are\\_sqm\\\\\n",
       "\\hline\n",
       "\t South Dakota & Pierre       &  0.853       & 77116       \\\\\n",
       "\t New York     & Albany       & 19.746       & 54555       \\\\\n",
       "\t Oregon       & Salem        &  3.970       & 98381       \\\\\n",
       "\t Vermont      & Montpelier   &  0.627       &  9616       \\\\\n",
       "\t Hawaii       & Honolulu     &  1.420       & 10931       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "state | capital | pop_mill | are_sqm | \n",
       "|---|---|---|---|---|\n",
       "| South Dakota | Pierre       |  0.853       | 77116        | \n",
       "| New York     | Albany       | 19.746       | 54555        | \n",
       "| Oregon       | Salem        |  3.970       | 98381        | \n",
       "| Vermont      | Montpelier   |  0.627       |  9616        | \n",
       "| Hawaii       | Honolulu     |  1.420       | 10931        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  state        capital    pop_mill are_sqm\n",
       "1 South Dakota Pierre      0.853   77116  \n",
       "2 New York     Albany     19.746   54555  \n",
       "3 Oregon       Salem       3.970   98381  \n",
       "4 Vermont      Montpelier  0.627    9616  \n",
       "5 Hawaii       Honolulu    1.420   10931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()\n",
    "Directory_State<-file.path(\"D:\",\"Documentos\",\"R\",\"states.csv\")\n",
    "Directory_State\n",
    "read.csv(Directory_State, stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read.delim and read.table\n",
    "Aside from .csv files, there are also the .txt files which are basically text files. You can import these functions with read.delim(). By default, it sets the sep argument to \"\\t\" (fields in a record are delimited by tabs) and the header argument to TRUE (the first row contains the field names).\n",
    "\n",
    "    read.delim(\"Name.txt\", stringsAsFactors = FALSE)\n",
    "    \n",
    "If you're dealing with more exotic flat file formats, you'll want to use read.table(). It's the most basic importing function; you can specify tons of different arguments in this function. Unlike read.csv() and read.delim(), the header argument defaults to FALSE and the sep argument is \"\" by default\n",
    "    \n",
    "    #read a file seperate by \"/\" \n",
    "    read.table(\"Name.txt\", header=TRUE, sep=\"/\", stringsAsFactors = FALSE)\n",
    "    \n",
    "Other properties that we can use, when we are defining our dataframe are :\n",
    "\n",
    "1. Name of columns\n",
    "2. Type of columns\n",
    "\n",
    "    `read.delim(\"my_file.txt\", col.names=c(\"c1\",\"c2\") colClasses = c(\"character\", \"numeric\"))`\n",
    "    \n",
    "This approach can be useful if you have some columns that should be factors and others that should be characters. You don't have to bother with stringsAsFactors anymore; just state for each column what the class should be.\n",
    "\n",
    "If a column is set to \"NULL\" in the colClasses vector, this column will be skipped and will not be loaded into the data frame.\n",
    "\n",
    "\n",
    "## 2. readr & data.table\n",
    "\n",
    "\n",
    "### readr: read_csv & read_tsv\n",
    "Now, you know how can you can import data to R through **utils** package, but we will see two additional package:\n",
    "\n",
    "1. readr\n",
    "2. data.table\n",
    "\n",
    "We start installing and using de readr package, so: \n",
    "\n",
    "    install.packages(\"readr\")\n",
    "    library(readr)\n",
    "\n",
    "but what about the syntax, well we have following differences:\n",
    "\n",
    "`Utils          readr\n",
    "read.table()  read_delim()\n",
    "read.csv()    read_csv ()\n",
    "read.delim()  read_tsv()  `\n",
    "\n",
    "Where you use read_csv() to easily read in CSV files, you use read_tsv() to easily read in TSV files. TSV is short for tab-separated values.\n",
    "\n",
    "### readr: read_delim\n",
    "\n",
    "`Utils          readr\n",
    "read.table()  read_delim()  `\n",
    "\n",
    "Just as read.table() was the main utils function, read_delim() is the main readr function.\n",
    "\n",
    "read_delim() takes two mandatory arguments:\n",
    "\n",
    "1. file: the file that contains the data\n",
    "2. delim: the character that separates the values in the data file\n",
    "\n",
    "Other columns that we could be using are:\n",
    "\n",
    "1. col_names\n",
    "\n",
    "\n",
    "Through **skip and n_max** you can control which part of your flat file you're actually importing into R.\n",
    "\n",
    "skip specifies the number of lines you're ignoring in the flat file before actually starting to import data.\n",
    "\n",
    "n_max specifies the number of lines you're actually importing.\n",
    "\n",
    "Say for example you have a CSV file with 20 lines, and set skip = 2 and n_max = 3, you're only reading in lines 3, 4 and 5 of the file\n",
    "\n",
    "**col_types**\n",
    "\n",
    "You can also specify which types the columns in your imported data frame should have. You can do this with col_types. If set to NULL, the default, functions from the readr package will try to find the correct types themselves. You can manually set the types with a string, where each character denotes the class of the column: \n",
    "    \n",
    "    c character, \n",
    "    d double, \n",
    "    i integer and \n",
    "    l logical \n",
    "    _ skips the column as a whole.\n",
    "    \n",
    "    \n",
    "**col_types with collectors**\n",
    "\n",
    "Another way of setting the types of the imported columns is using collectors. Collector functions can be passed in a list() to the col_types argument of read_ functions to tell them how to interpret values in a column.\n",
    "\n",
    "For a complete list of collector functions, you can take a look at the collector documentation. For this exercise you will need two collector functions:\n",
    "\n",
    "1. col_integer(): the column should be interpreted as an integer.\n",
    "2. col_factor(levels, ordered = FALSE): the column should be interpreted as a factor with levels.\n",
    "\n",
    "### data.table \n",
    "It´s necessary to install this package so:\n",
    "\n",
    "    #install package data.table\n",
    "    install.packages(\"data.table\")\n",
    "    library(data.table)\n",
    "\n",
    "it´s very similar to `read.table()` so what's the difference between these two function? well, data.table() is a improved version from read.table(), because it´is more faster, convenient and customizable.\n",
    "\n",
    "**fread**\n",
    "You still remember how to use read.table(), right? Well, fread() is a function that does the same job with very similar arguments. It is extremely easy to use and blazingly fast! Often, simply specifying the path to the file is enough to successfully import your data.\n",
    "\n",
    "**read: more advanced use**\n",
    "Now that you know the basics about fread(), you should know about two arguments of the function: drop and select, to drop or select variables of interest.\n",
    "\n",
    "Suppose you have a dataset that contains 5 variables and you want to keep the first and fifth variable, named \"a\" and \"e\". The following options will all do the trick:\n",
    "\n",
    "    fread(\"path/to/file.txt\", drop = 2:4)\n",
    "    fread(\"path/to/file.txt\", select = c(1, 5))\n",
    "    fread(\"path/to/file.txt\", drop = c(\"b\", \"c\", \"d\"))\n",
    "    fread(\"path/to/file.txt\", select = c(\"a\", \"e\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Importing Excel data\n",
    "\n",
    "Excel is a very widely used data analysis tool. If you prefer to do your analyses in R, though, you'll need an understanding of importing CSV data into R. This chapter will show you how to use readxl and gdata to do so.\n",
    "\n",
    "### readxl package\n",
    "This new package bring with it two function very useful:\n",
    "\n",
    "    excel_sheets(\"Name WorkBook Excel.xlsx\") list differents sheets\n",
    "    read_excel() actually import data into R\n",
    "\n",
    "so we will start installing the package:\n",
    "\n",
    "    #install package readxl\n",
    "    install.packages(\"readxl\")\n",
    "    library(readxl)\n",
    "\n",
    "To able open a book we have:\n",
    "\n",
    "    data <- read_excel(\"data.xlsx\", sheet = \"my_sheet\")\n",
    "    \n",
    " This call simply imports the sheet with the name \"my_sheet\" from the \"data.xlsx\" file. You can also pass a number to the sheet argument; this will cause read_excel() to import the sheet with the given sheet number. sheet = 1 will import the first sheet, sheet = 2 will import the second sheet, and so on.\n",
    " \n",
    "If you want to read multiple sheets, you could use a lapply:\n",
    " \n",
    "     my_workbook <- lapply(excel_sheets(\"data.xlsx\"),\n",
    "                          read_excel,\n",
    "                          path = \"data.xlsx\")\n",
    "Apart from path and sheet, there are several other arguments you can specify in read_excel(), like:\n",
    "\n",
    "    read_excel(path, sheet=1, \n",
    "               col_names = TRUE/FALSE #False then R assigns names itself \n",
    "               col_types = NULL, # by default it´s Null,but we can specify the type of our data *\n",
    "               skip = 0 ) \n",
    "\n",
    "`*`We have text,date,numeric and blank (Note: if we use blank we ignore the column)\n",
    "\n",
    "By default **col_names** is TRUE, denoting whether the first row in the Excel sheets contains the column names. If this is not the case, you can set col_names to FALSE. In this case, R will choose column names for you. You can also choose to set col_names to a character vector with names for each column. It works exactly the same as in the readr package.\n",
    "    \n",
    "Another argument that can be very useful when reading in Excel files that are less tidy, is **skip**. With skip, you can tell R to ignore a specified number of rows inside the Excel sheets you're trying to pull data from. Have a look at this example:\n",
    "\n",
    "    read_excel(\"data.xlsx\", skip = 15)\n",
    "    \n",
    "In this case, the first 15 rows in the first sheet of \"data.xlsx\" are ignored.\n",
    "\n",
    "### gdata package\n",
    "\n",
    "It´s other alternative package to read excel file, \n",
    "\n",
    "1. Entire suite of tools for data manipulation.\n",
    "2. gdata use **Perl** (other lenguage to programmation) to read excel file ,Perl convert our Excel to CSV File then R read thi file using default package **read.csv** but remember that this is a extension of **read.table**\n",
    "3. It´s a elegant extesion of **utils package**\n",
    "\n",
    "    `\n",
    "    ##install gdata\n",
    "    install.packages(\"gdata\")\n",
    "    library(gdata)`\n",
    "\n",
    "Remember how read.xls() actually works? It basically comes down to two steps: converting the Excel file to a .csv file using a Perl script, and then reading that .csv file with the read.csv() function that is loaded by default in R, through the utils package.\n",
    "\n",
    "This means that all the options that you can specify in read.csv(), can also be specified in read.xls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4 Reproducible Excel work with XLConnect\n",
    "Next to importing data from Excel, you can take things one step further with XLConnect\n",
    "\n",
    "Imagine this situation, you work in a big company and all their analysis are on excel file so you have to work on and deliver this excel files but you work in R so you need a way to work and reproduce way, thanks a good exist one packege that do that, it´s a bridge between Excel to R, it allow you to do all things you doing in excel but in R\n",
    "\n",
    "    #Package XLConnect\n",
    "    install.packages(\"XLConnect\")\n",
    "    \n",
    " Note it´s very possible that we have problems with this package because sometimes it´s necesarry to install Oracle´s Jave Development Kit (JDK) or lookink for in Goole our error.\n",
    "\n",
    "### Reading sheets\n",
    "\n",
    "When working with XLConnect, the first step will be to load a workbook in your R session with loadWorkbook(); this function will build a \"bridge\" between your Excel file and your R session.\n",
    "    \n",
    "    my_book<-loadWorkbook(\"urbanpop.xlsx\")\n",
    "\n",
    "### List and read Excel sheets\n",
    "Just as readxl and gdata, you can use XLConnect to import data from Excel file into R.\n",
    "\n",
    "To list the sheets in an Excel file, use getSheets(). To actually import data from a sheet, you can use readWorksheet(). Both functions require an XLConnect workbook object as the first argument.\n",
    "\n",
    "    # List the sheets in my_book\n",
    "    getSheets(my_book)\n",
    "\n",
    "    # Import the second sheet in my_book\n",
    "    readWorksheet(my_book, sheet=2)\n",
    "    \n",
    "### Customize readWorksheet\n",
    "To get a clear overview about urbanpop.xlsx without having to open up the Excel file, you can execute the following code:\n",
    "\n",
    "    my_book <- loadWorkbook(\"urbanpop.xlsx\")\n",
    "    sheets <- getSheets(my_book)\n",
    "    all <- lapply(sheets, readWorksheet, object = my_book)\n",
    "    str(all)\n",
    "    \n",
    "### Adapting Sheets \n",
    "until now we didn't see nothing new, we can do it using the previous packages but what happen if we want to create a new sheet, modify the name, delete a sheet , if we want work on formulas or format, it´s the reason this package it´s amazing.\n",
    "\n",
    "### New Sheets\n",
    "Where readxl and gdata were only able to import Excel data, XLConnect's approach of providing an actual interface to an Excel file makes it able to edit your Excel files from inside R. In this exercise, you'll create a new sheet.\n",
    "\n",
    "    # Add a worksheet to my_book, named \"data_summary\"\n",
    "    createSheet(my_book, name = \"data_summary\")\n",
    "\n",
    "    # Use getSheets() on my_book\n",
    "    getSheets(my_book)\n",
    "    \n",
    "    # Add data in summ to \"data_summary\" sheet\n",
    "    writeWorksheet(my_book,summ, sheet=\"data_summary\")\n",
    "\n",
    "    # Save workbook as summary.xlsx\n",
    "    saveWorkbook(my_book,file=\"summary.xlsx\")\n",
    "    \n",
    "    # Rename \"data_summary\" sheet to \"summary\"\n",
    "    renameSheet(my_book,\"data_summary\",\"summary\")\n",
    "\n",
    "    # Print out sheets of my_book\n",
    "    getSheets(my_book)\n",
    "\n",
    "    # Save workbook to \"renamed.xlsx\"\n",
    "    saveWorkbook(my_book, file=\"renamed.xlsx\")\n",
    "    \n",
    "    # Remove the fourth sheet\n",
    "    removeSheet(my_book,\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in contrib.url(repos, \"source\"): trying to use CRAN without setting a mirror\n",
     "output_type": "error",
     "traceback": [
      "Error in contrib.url(repos, \"source\"): trying to use CRAN without setting a mirror\nTraceback:\n",
      "1. install.packages(\"XLConnect\")",
      "2. contrib.url(repos, \"source\")",
      "3. stop(\"trying to use CRAN without setting a mirror\")"
     ]
    }
   ],
   "source": [
    "#Package XLConnect\n",
    "install.packages(\"XLConnect\")\n",
    "\n",
    "# urbanpop.xlsx is available in your working directory\n",
    "library(XLConnect)\n",
    "\n",
    "#To know our actual work directory \n",
    "getwd()\n",
    "\n",
    "# Set the working directory or change our directory\n",
    "setwd(\"D:/Documentos/R\")\n",
    "\n",
    "# Load the XLConnect package\n",
    "my_book<-loadWorkbook(\"urbanpop.xlsx\")\n",
    "\n",
    "# Build connection to urbanpop.xlsx: my_book\n",
    "\n",
    "# Print out the class of my_book\n",
    "class(my_book)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

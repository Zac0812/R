{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Data Visualization with ggplot2\n",
    "link: https://www.datacamp.com/search?facets%5Btechnology%5D%5B%5D=r&facets%5Btopic%5D%5B%5D=Data+Visualization&tab=courses\n",
    "\n",
    "course: https://learn.datacamp.com/courses/intermediate-data-visualization-with-ggplot2\n",
    "\n",
    "### Course Description\n",
    "This ggplot2 course builds on your knowledge from the introductory course to produce meaningful explanatory plots. Statistics will be calculated on the fly and you’ll see how Coordinates and Facets aid in communication. You’ll also explore details of data visualization best practices with ggplot2 to help make sure you have a sound understanding of what works and why. By the end of the course, you’ll have all the tools needed to make a custom plotting function to explore a large data set, combining statistics and excellent visuals.\n",
    "\n",
    "\n",
    "### Note how can Resizing plots in the R kernel for Jupyter notebooks\n",
    "https://blog.revolutionanalytics.com/2015/09/resizing-plots-in-the-r-kernel-for-jupyter-notebooks.html\n",
    "\n",
    "    library(repr)\n",
    "\n",
    "    # Change plot size to 4 x 3\n",
    "    options(repr.plot.width=4, repr.plot.height=3)\n",
    "    \n",
    "### Note2 Generate a table \n",
    "\n",
    "https://www.tablesgenerator.com/markdown_tables\n",
    "\n",
    "\n",
    "other: Book: machine learning with R by Brett Lantz\n",
    "Learn about `attr` function\n",
    "\n",
    "\n",
    "Laying out multiple plots on a page:  https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html\n",
    "\n",
    "### Note 3 - DataFrames\n",
    "\n",
    "We have troubles in the moment to load our dataset but if we used `gascon(url())` or onlye `url()` we can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 3.5.3\"\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.5.3\"Warning message:\n",
      "\"package 'gridExtra' was built under R version 3.5.3\"\n",
      "Attaching package: 'gridExtra'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(gridExtra)\n",
    "data(mtcars)\n",
    "\n",
    "mtcars$fcyl<-factor(mtcars$cyl, levels = c(\"4\",\"6\",\"8\"))\n",
    "mtcars$fam<-factor(mtcars$am, labels = c(\"automatic\",\"manual\"),  levels  = c (1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Statistics\n",
    "A picture paints a thousand words, which is why R ggplot2 is such a powerful tool for graphical data analysis. In this chapter, you’ll progress from simply plotting data to applying a variety of statistical methods. These include a variety of linear models, descriptive and inferential statistics (mean, standard deviation and confidence intervals) and custom functions.\n",
    "\n",
    "### 1.1) (video) Stats with geoms\n",
    "\n",
    "welcome to the second ggplot2 course on data visualization, here we are going to build on the skills you learned during the first course, we will examine the following 3 layers in detail:\n",
    "\n",
    "1. Statistics\n",
    "2. coordinates\n",
    "3. facets\n",
    "\n",
    "so let's start with the statistics, there are two category of functions in this family.\n",
    "\n",
    "- those are called from within `geom` \n",
    "- those are called independently \n",
    "\n",
    "as maybe you guess all statistics start with `stats_` .\n",
    "\n",
    "we already saw `stats_` funciontions, when we use `geom_histrogram()` ,recall that under the hood, this calls `stat_bin` to summarize total count in each group, but we can obtain the same result with the `geom_bar`,  but if we call the `stat_count()` directely, we will obtain the same result.\n",
    "\n",
    "so we can see specif `geom` and specif `stat` functions are related \n",
    "\n",
    "### 1.2 (video) Stats: sum and quantile\n",
    "now we will discuss two useful functions `geom_count` and `geom_quantile` in the last course we saw 4 ways to overcome the overplotting.\n",
    "\n",
    "- `geom_count` counts the number of observations in each location and then maps the counts onto sides points area, remeber that each `geom` can be associate a `stat` directely as e.g `stat_count` in this case. \n",
    "- `geom_quantile`  This fits a quantile regression to the data and draws the fitted quantiles with lines or we can use stat_quantile().\n",
    "\n",
    "\n",
    "| Cause Over-Plotting             | Solutiones               | Here...      |\n",
    "|---------------------------------|--------------------------|--------------|\n",
    "| Large Dataset                   | alpha                    |              |\n",
    "| Aligned values on a single axis | alpha + change possition |              |\n",
    "| Low precision data              | jitter                   | geom_count() |\n",
    "| Integer data                    | jitter                   | geom_count() |\n",
    "\n",
    "Wen you have two integer variable one solution, is jittering with transparency. Another solution is to use `stat_sum()`, which calculates the total number of overlapping observations and maps that onto the size aesthetic.\n",
    "\n",
    "`stat_sum()` allows a special variable, ..`prop`.., to show the proportion of values within the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Stats outside geoms\n",
    "Let's see some statistics that you can call directly, the typical way to summarize the data is with the mean, standard deviation or confidence of the 95% interval, we can calculate them manually or do it directly in ggplot2.\n",
    "\n",
    "or can use other package e.g\n",
    "\n",
    "    set.seed(123)\n",
    "    xx <- rnorm(100)\n",
    "    # Hmisc\n",
    "    library(Hmisc)\n",
    "    smean.sdl(xx, mult = 1)  # 1 sd\n",
    "    \n",
    "but we can do it with ggplot 2 `mean_sdl(xx, mult = 1)`\n",
    "\n",
    "In summary we can use some kind this function into: \n",
    "\n",
    "- stat_summary(), summarize y values at distinct x values.\n",
    "- stat_function(), compute y values from a function of x values.\n",
    "- stat_qq(), perform calculations for a quantile-quantile plot.\n",
    "\n",
    "`Summary statistics` refers to a combination of location (mean or median) and spread (standard deviation or confidence interval).\n",
    "\n",
    "These metrics are calculated in `stat_summary()` by passing a function to the `fun.data` argument. `mean_sdl()`, calculates multiples of the standard deviation and `mean_cl_normal()` calculates the t-corrected 95% CI.\n",
    "\n",
    "Arguments to the data function are passed to `stat_summary()`'s `fun.args` argument as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0904059086362066"
      ],
      "text/latex": [
       "0.0904059086362066"
      ],
      "text/markdown": [
       "0.0904059086362066"
      ],
      "text/plain": [
       "[1] 0.09040591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.822409971044772</li>\n",
       "\t<li>1.00322178831719</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.822409971044772\n",
       "\\item 1.00322178831719\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.822409971044772\n",
       "2. 1.00322178831719\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.822410  1.003222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123)\n",
    "xx <- rnorm(100)\n",
    "mean(xx)\n",
    "mean(xx) + (sd(xx) * c(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Coordinates\n",
    "\n",
    "The Coordinates layers offer specific and very useful tools for efficiently and accurately communicating data. Here we’ll look at the various ways of effectively using these layers, so you can clearly visualize lognormal datasets, variables with units, and periodic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
